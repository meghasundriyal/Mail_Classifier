{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <H1> ROCCHIO CLASSIFIER </H1>\n",
    "    <br>\n",
    "======================================================================================================================<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 1: IMPORTING LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer  \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import math \n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 2: LOADING DATASET\n",
    "\n",
    "Load the required dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sno</th>\n",
       "      <th>time</th>\n",
       "      <th>subject</th>\n",
       "      <th>sender</th>\n",
       "      <th>body</th>\n",
       "      <th>folder</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Tue, 17 Sep 2019 09:51:40 -0700</td>\n",
       "      <td>Megha, your profile is getting hits</td>\n",
       "      <td>=?UTF-8?B?TGlua2VkSW4=?= &lt;linkedin@e.linkedin....</td>\n",
       "      <td>Please view this email in a browser: \\r\\nhttps...</td>\n",
       "      <td>Inbox</td>\n",
       "      <td>Social</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Sun, 29 Sep 2019 02:50:00 +0000 (UTC)</td>\n",
       "      <td>Building A Logistic Regression in Python, Step...</td>\n",
       "      <td>\"Medium Daily Digest\" &lt;noreply@medium.com&gt;</td>\n",
       "      <td>Today's highlights\\r\\n\\r\\nBuilding A Logistic ...</td>\n",
       "      <td>Inbox</td>\n",
       "      <td>Updates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Mon, 12 Aug 2019 01:43:21 +0000 (GMT)</td>\n",
       "      <td>Help us protect you: Security advice from Google</td>\n",
       "      <td>Google &lt;no-reply@accounts.google.com&gt;</td>\n",
       "      <td>Confirm your recovery phone\\r\\n\\r\\nmegha.mcs18...</td>\n",
       "      <td>Inbox</td>\n",
       "      <td>Personal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Mon, 30 Sep 2019 08:02:38 +0000 (UTC)</td>\n",
       "      <td>Megha, start a conversation with your new conn...</td>\n",
       "      <td>Kashish Gupta via LinkedIn &lt;invitations@linked...</td>\n",
       "      <td>Kashish Gupta has accepted your invitation. Le...</td>\n",
       "      <td>Inbox</td>\n",
       "      <td>Social</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Wed, 21 Aug 2019 16:21:31 +0000 (UTC)</td>\n",
       "      <td>Prepare for a coding interview in Python</td>\n",
       "      <td>\"Mari from DataCamp\" &lt;team@datacamp.com&gt;</td>\n",
       "      <td>Hi there,\\r\\n\\r\\nWe have 10 new courses coveri...</td>\n",
       "      <td>Inbox</td>\n",
       "      <td>Promotions</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sno                                   time  \\\n",
       "0    1        Tue, 17 Sep 2019 09:51:40 -0700   \n",
       "1    2  Sun, 29 Sep 2019 02:50:00 +0000 (UTC)   \n",
       "2    3  Mon, 12 Aug 2019 01:43:21 +0000 (GMT)   \n",
       "3    4  Mon, 30 Sep 2019 08:02:38 +0000 (UTC)   \n",
       "4    5  Wed, 21 Aug 2019 16:21:31 +0000 (UTC)   \n",
       "\n",
       "                                             subject  \\\n",
       "0                Megha, your profile is getting hits   \n",
       "1  Building A Logistic Regression in Python, Step...   \n",
       "2   Help us protect you: Security advice from Google   \n",
       "3  Megha, start a conversation with your new conn...   \n",
       "4           Prepare for a coding interview in Python   \n",
       "\n",
       "                                              sender  \\\n",
       "0  =?UTF-8?B?TGlua2VkSW4=?= <linkedin@e.linkedin....   \n",
       "1         \"Medium Daily Digest\" <noreply@medium.com>   \n",
       "2              Google <no-reply@accounts.google.com>   \n",
       "3  Kashish Gupta via LinkedIn <invitations@linked...   \n",
       "4           \"Mari from DataCamp\" <team@datacamp.com>   \n",
       "\n",
       "                                                body folder        label  \n",
       "0  Please view this email in a browser: \\r\\nhttps...  Inbox       Social  \n",
       "1  Today's highlights\\r\\n\\r\\nBuilding A Logistic ...  Inbox      Updates  \n",
       "2  Confirm your recovery phone\\r\\n\\r\\nmegha.mcs18...  Inbox     Personal  \n",
       "3  Kashish Gupta has accepted your invitation. Le...  Inbox       Social  \n",
       "4  Hi there,\\r\\n\\r\\nWe have 10 new courses coveri...  Inbox   Promotions  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mails_dataset = pd.read_csv('Dataset/trial_spam.csv', encoding = 'latin-1')\n",
    "mails_dataset = pd.read_csv('Dataset/emails.csv', encoding = 'latin-1')\n",
    "mails_dataset.head()           #show first 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 3: FEATURE SELECTION\n",
    "\n",
    "Select the relevant features, important for mail classification. We can see that column Unamed are irrelevant for our classifier. Thus, we need to remove them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sno</th>\n",
       "      <th>subject</th>\n",
       "      <th>body</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Megha, your profile is getting hits</td>\n",
       "      <td>Please view this email in a browser: \\r\\nhttps...</td>\n",
       "      <td>Social</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Building A Logistic Regression in Python, Step...</td>\n",
       "      <td>Today's highlights\\r\\n\\r\\nBuilding A Logistic ...</td>\n",
       "      <td>Updates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Help us protect you: Security advice from Google</td>\n",
       "      <td>Confirm your recovery phone\\r\\n\\r\\nmegha.mcs18...</td>\n",
       "      <td>Personal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Megha, start a conversation with your new conn...</td>\n",
       "      <td>Kashish Gupta has accepted your invitation. Le...</td>\n",
       "      <td>Social</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Prepare for a coding interview in Python</td>\n",
       "      <td>Hi there,\\r\\n\\r\\nWe have 10 new courses coveri...</td>\n",
       "      <td>Promotions</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sno                                            subject  \\\n",
       "0    1                Megha, your profile is getting hits   \n",
       "1    2  Building A Logistic Regression in Python, Step...   \n",
       "2    3   Help us protect you: Security advice from Google   \n",
       "3    4  Megha, start a conversation with your new conn...   \n",
       "4    5           Prepare for a coding interview in Python   \n",
       "\n",
       "                                                body        label  \n",
       "0  Please view this email in a browser: \\r\\nhttps...       Social  \n",
       "1  Today's highlights\\r\\n\\r\\nBuilding A Logistic ...      Updates  \n",
       "2  Confirm your recovery phone\\r\\n\\r\\nmegha.mcs18...     Personal  \n",
       "3  Kashish Gupta has accepted your invitation. Le...       Social  \n",
       "4  Hi there,\\r\\n\\r\\nWe have 10 new courses coveri...   Promotions  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop undesirable columns\n",
    "#drop_list = ['Unnamed: 3', 'Unnamed: 4','Unnamed: 5','Unnamed: 6']\n",
    "mails_dataset.drop(mails_dataset.columns.difference(['sno','subject','body','label']), axis = 1, inplace = True)\n",
    "\n",
    "mails_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mails_dataset['Message'] = mails_dataset[['subject', 'body']].apply(lambda x: ' '.join(x.astype(str)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DocID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Social</td>\n",
       "      <td>Megha, your profile is getting hits Please vie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Updates</td>\n",
       "      <td>Building A Logistic Regression in Python, Step...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Personal</td>\n",
       "      <td>Help us protect you: Security advice from Goog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Social</td>\n",
       "      <td>Megha, start a conversation with your new conn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Promotions</td>\n",
       "      <td>Prepare for a coding interview in Python Hi th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DocID        Label                                            Message\n",
       "0      1       Social  Megha, your profile is getting hits Please vie...\n",
       "1      2      Updates  Building A Logistic Regression in Python, Step...\n",
       "2      3     Personal  Help us protect you: Security advice from Goog...\n",
       "3      4       Social  Megha, start a conversation with your new conn...\n",
       "4      5   Promotions  Prepare for a coding interview in Python Hi th..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rename the columns, to make it easy to read and manipulate\n",
    "mails_dataset.rename(columns = {'sno': 'DocID', 'label': 'Label'}, inplace = True)\n",
    "mails_dataset.drop(['subject','body'], axis = 1, inplace = True)\n",
    "\n",
    "mails_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "681"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mails_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Personal      238\n",
       " Social        151\n",
       " Forums        141\n",
       " Updates       119\n",
       " Promotions     32\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mails_dataset['Label'].value_counts()  #count number of each Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "681"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_mails = mails_dataset.shape[0]            #total number on instances in our dataset\n",
    "total_mails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 4: DATA PREPROCESSING\n",
    "\n",
    "We need to clean our data for further processing. Emails may contain a lot of undesirable characters like punctuation marks, stop words, digits, etc which may not be helpful in detecting the spam email"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  A. Convert to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DocID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Social</td>\n",
       "      <td>megha, your profile is getting hits please vie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Updates</td>\n",
       "      <td>building a logistic regression in python, step...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Personal</td>\n",
       "      <td>help us protect you: security advice from goog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Social</td>\n",
       "      <td>megha, start a conversation with your new conn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Promotions</td>\n",
       "      <td>prepare for a coding interview in python hi th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DocID        Label                                            Message\n",
       "0      1       Social  megha, your profile is getting hits please vie...\n",
       "1      2      Updates  building a logistic regression in python, step...\n",
       "2      3     Personal  help us protect you: security advice from goog...\n",
       "3      4       Social  megha, start a conversation with your new conn...\n",
       "4      5   Promotions  prepare for a coding interview in python hi th..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert the data into lower case\n",
    "mails_dataset['Message'] =  mails_dataset['Message'].str.lower()\n",
    "mails_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Convert categorical values to numbers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DocID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Social</td>\n",
       "      <td>megha, your profile is getting hits please vie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Updates</td>\n",
       "      <td>building a logistic regression in python, step...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Personal</td>\n",
       "      <td>help us protect you: security advice from goog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Social</td>\n",
       "      <td>megha, start a conversation with your new conn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Promotions</td>\n",
       "      <td>prepare for a coding interview in python hi th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DocID        Label                                            Message\n",
       "0      1       Social  megha, your profile is getting hits please vie...\n",
       "1      2      Updates  building a logistic regression in python, step...\n",
       "2      3     Personal  help us protect you: security advice from goog...\n",
       "3      4       Social  megha, start a conversation with your new conn...\n",
       "4      5   Promotions  prepare for a coding interview in python hi th..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    Personal : 0\n",
    "    Social : 1\n",
    "    Forums : 2\n",
    "    Updates : 3\n",
    "    Promotions : 4\n",
    "    \n",
    "'''\n",
    "#mails_dataset['label'] = mails_dataset['label'].map({'ham': 0, 'spam': 1})\n",
    "#mails_dataset['label'] = mails_dataset['label'].map({'Personal': 0, 'Social' : 1, 'Forums' : 2,'Updates' : 3, 'Promotions' : 4})\n",
    "mails_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mails_dataset['Label']=mails_dataset['Label'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DocID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>megha, your profile is getting hits please vie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>building a logistic regression in python, step...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>help us protect you: security advice from goog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>megha, start a conversation with your new conn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>prepare for a coding interview in python hi th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DocID  Label                                            Message\n",
       "0      1      1  megha, your profile is getting hits please vie...\n",
       "1      2      3  building a logistic regression in python, step...\n",
       "2      3      0  help us protect you: security advice from goog...\n",
       "3      4      1  megha, start a conversation with your new conn...\n",
       "4      5      4  prepare for a coding interview in python hi th..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary = {'Personal': 0, 'Social' : 1, 'Forums' : 2,'Updates' : 3, 'Promotions' : 4}\n",
    "mails_dataset=mails_dataset.replace({\"Label\": dictionary})\n",
    "mails_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Remove digits and punctutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DocID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>megha, your profile is getting hits please vie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>building a logistic regression in python, step...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>help us protect you: security advice from goog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>megha, start a conversation with your new conn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>prepare for a coding interview in python hi th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DocID  Label                                            Message\n",
       "0      1      1  megha, your profile is getting hits please vie...\n",
       "1      2      3  building a logistic regression in python, step...\n",
       "2      3      0  help us protect you: security advice from goog...\n",
       "3      4      1  megha, start a conversation with your new conn...\n",
       "4      5      4  prepare for a coding interview in python hi th..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove all digits\n",
    "mails_dataset['Message'] = mails_dataset['Message'].str.replace('\\d+.\\d+', '')\n",
    "mails_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DocID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>megha your profile is getting hits please view...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>building a logistic regression in python step ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>help us protect you security advice from googl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>megha start a conversation with your new conne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>prepare for a coding interview in python hi th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DocID  Label                                            Message\n",
       "0      1      1  megha your profile is getting hits please view...\n",
       "1      2      3  building a logistic regression in python step ...\n",
       "2      3      0  help us protect you security advice from googl...\n",
       "3      4      1  megha start a conversation with your new conne...\n",
       "4      5      4  prepare for a coding interview in python hi th..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "     ^   :  Not these characters\n",
    "     \\w  :  Word characters\n",
    "     \\s  :  Space characters\n",
    "\n",
    "    Replace any character that is not a word character or a space character with nothing/blank.\n",
    "    \n",
    "'''\n",
    "mails_dataset['Message'] = mails_dataset['Message'].str.replace('[^\\w\\s]', '')\n",
    "mails_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'megha your profile is getting hits please view this email in a browser \\r\\nhttpselinkedincompubsfformlink_ri_x0gzc2x3dyqpglljhjlyqgn9zfezbymbzf35enzgsrm98sgilihzbazbkwzdwezdzebuncrk6homprvxmtx3dyqpglljhjlyqgu2ukmcdioiucuedsd8nm5wgjocvkgokgzgni1qryl75on6zdv7zcwcdf_ei_evpx2zyzpfwmdastehmmwcjongvnq7xm_nijszrbxhbpzjyjg3d3d\\r\\n\\r\\nif you need assistance or have questions please contact linkedin customer service \\r\\nhttpselinkedincompubcc_ri_x0gzc2x3dyqpglljhjlyqgn9zfezbymbzf35enzgsrm98sgilihzbazbkwzdwezdzebuncrk6homprvxtpkx3dswtdcsy_ei_eolaggf4snmvxff7kuckuwmuru2mcbogxku09vjwvrf62zxhf1xwquo9ggtofxh0anawteojssxgjg3d3d \\r\\n\\r\\nthis is an occasional email to help you get the most out of linkedin unsubscribe \\r\\nhttpselinkedincompubcc_ri_x0gzc2x3dyqpglljhjlyqgn9zfezbymbzf35enzgsrm98sgilihzbazbkwzdwezdzebuncrk6homprvxtpkx3dswsuusy_ei_eolaggf4snmvxff7kuckuwmuru2mcbogxku09vj9mjfzbx7rmjiwphlqcq2lo9bykgkwjfw_qmhspmnpfx8wuujzy1pn_2zuq52as8etm7nsukdkxvmqo91cluos8gymlqczsiohieeg1emqgvotjxusdabmuafbmgoo1pv5ih8vaciga3ltbng9xojg3d3d\\r\\n\\r\\nthis email was intended for megha learn why we include this httphelplinkedincomappanswersglobalidfteng\\r\\n\\r\\ncopyright  linkedin corporation all rights reserved linkedin corp  west maude avenue sunnyvale ca \\r\\n\\r\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_mail = mails_dataset.iloc[0]\n",
    "sample_mail['Message']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Convert all the slang words to corresponding formal words\n",
    "\n",
    "Slang is the popular informal form of a word or group of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dictionary of slang words and their corresponding terms\n",
    "\n",
    "slang_list = {'u': 'you', 'r': 'are', 'd': \"the\", 'urs' : 'yours', 'wkly' : 'weekly', 'st' : 'such that', \n",
    "              'txt': 'text','comp': 'competition', 'prctc' : 'practice', 'dffrnc': 'difference', 'y': 'why', \n",
    "              'f9':'fine', 'tkts': 'tickets', 'csh': 'cash', 'phn': 'phone', 'im': 'i am', 'm': 'am', \n",
    "              'spcl': 'special', 'fone': 'phone', 'wks' : 'weeks', 'å': 'a', 'n': 'and', 'wat':'what'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "megha your profile is getting hits please view this email in a browser \r\n",
      "httpselinkedincompubsfformlink_ri_x0gzc2x3dyqpglljhjlyqgn9zfezbymbzf35enzgsrm98sgilihzbazbkwzdwezdzebuncrk6homprvxmtx3dyqpglljhjlyqgu2ukmcdioiucuedsd8nm5wgjocvkgokgzgni1qryl75on6zdv7zcwcdf_ei_evpx2zyzpfwmdastehmmwcjongvnq7xm_nijszrbxhbpzjyjg3d3d\r\n",
      "\r\n",
      "if you need assistance or have questions please contact linkedin customer service \r\n",
      "httpselinkedincompubcc_ri_x0gzc2x3dyqpglljhjlyqgn9zfezbymbzf35enzgsrm98sgilihzbazbkwzdwezdzebuncrk6homprvxtpkx3dswtdcsy_ei_eolaggf4snmvxff7kuckuwmuru2mcbogxku09vjwvrf62zxhf1xwquo9ggtofxh0anawteojssxgjg3d3d \r\n",
      "\r\n",
      "this is an occasional email to help you get the most out of linkedin unsubscribe \r\n",
      "httpselinkedincompubcc_ri_x0gzc2x3dyqpglljhjlyqgn9zfezbymbzf35enzgsrm98sgilihzbazbkwzdwezdzebuncrk6homprvxtpkx3dswsuusy_ei_eolaggf4snmvxff7kuckuwmuru2mcbogxku09vj9mjfzbx7rmjiwphlqcq2lo9bykgkwjfw_qmhspmnpfx8wuujzy1pn_2zuq52as8etm7nsukdkxvmqo91cluos8gymlqczsiohieeg1emqgvotjxusdabmuafbmgoo1pv5ih8vaciga3ltbng9xojg3d3d\r\n",
      "\r\n",
      "this email was intended for megha learn why we include this httphelplinkedincomappanswersglobalidfteng\r\n",
      "\r\n",
      "copyright  linkedin corporation all rights reserved linkedin corp  west maude avenue sunnyvale ca \r\n",
      "\r\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'megha your profile is getting hits please view this email in a browser httpselinkedincompubsfformlink_ri_x0gzc2x3dyqpglljhjlyqgn9zfezbymbzf35enzgsrm98sgilihzbazbkwzdwezdzebuncrk6homprvxmtx3dyqpglljhjlyqgu2ukmcdioiucuedsd8nm5wgjocvkgokgzgni1qryl75on6zdv7zcwcdf_ei_evpx2zyzpfwmdastehmmwcjongvnq7xm_nijszrbxhbpzjyjg3d3d if you need assistance or have questions please contact linkedin customer service httpselinkedincompubcc_ri_x0gzc2x3dyqpglljhjlyqgn9zfezbymbzf35enzgsrm98sgilihzbazbkwzdwezdzebuncrk6homprvxtpkx3dswtdcsy_ei_eolaggf4snmvxff7kuckuwmuru2mcbogxku09vjwvrf62zxhf1xwquo9ggtofxh0anawteojssxgjg3d3d this is an occasional email to help you get the most out of linkedin unsubscribe httpselinkedincompubcc_ri_x0gzc2x3dyqpglljhjlyqgn9zfezbymbzf35enzgsrm98sgilihzbazbkwzdwezdzebuncrk6homprvxtpkx3dswsuusy_ei_eolaggf4snmvxff7kuckuwmuru2mcbogxku09vj9mjfzbx7rmjiwphlqcq2lo9bykgkwjfw_qmhspmnpfx8wuujzy1pn_2zuq52as8etm7nsukdkxvmqo91cluos8gymlqczsiohieeg1emqgvotjxusdabmuafbmgoo1pv5ih8vaciga3ltbng9xojg3d3d this email was intended for megha learn why we include this httphelplinkedincomappanswersglobalidfteng copyright linkedin corporation all rights reserved linkedin corp west maude avenue sunnyvale ca'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#replace slang with formal word\n",
    "\n",
    "sample_mail = mails_dataset.iloc[0]\n",
    "message = sample_mail['Message']\n",
    "print(message)\n",
    "\n",
    "new_message = ' '.join(slang_list[i] if i in slang_list else i for i in message.split())\n",
    "new_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DocID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>megha your profile is getting hits please view...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>building a logistic regression in python step ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>help us protect you security advice from googl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>megha start a conversation with your new conne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>prepare for a coding interview in python hi th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DocID  Label                                            Message\n",
       "0      1      1  megha your profile is getting hits please view...\n",
       "1      2      3  building a logistic regression in python step ...\n",
       "2      3      0  help us protect you security advice from googl...\n",
       "3      4      1  megha start a conversation with your new conne...\n",
       "4      5      4  prepare for a coding interview in python hi th..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#applying to all rows\n",
    "\n",
    "def convert_slangs(row):\n",
    "    message = row['Message']\n",
    "    new_message = ' '.join(slang_list[i] if i in slang_list else i for i in message.split())\n",
    "    return new_message\n",
    "\n",
    "mails_dataset['Message'] = mails_dataset.apply(convert_slangs, axis=1)\n",
    "mails_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DocID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Message</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>megha your profile is getting hits please view...</td>\n",
       "      <td>[megha, your, profile, is, getting, hits, plea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>building a logistic regression in python step ...</td>\n",
       "      <td>[building, a, logistic, regression, in, python...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>help us protect you security advice from googl...</td>\n",
       "      <td>[help, us, protect, you, security, advice, fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>megha start a conversation with your new conne...</td>\n",
       "      <td>[megha, start, a, conversation, with, your, ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>prepare for a coding interview in python hi th...</td>\n",
       "      <td>[prepare, for, a, coding, interview, in, pytho...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DocID  Label                                            Message  \\\n",
       "0      1      1  megha your profile is getting hits please view...   \n",
       "1      2      3  building a logistic regression in python step ...   \n",
       "2      3      0  help us protect you security advice from googl...   \n",
       "3      4      1  megha start a conversation with your new conne...   \n",
       "4      5      4  prepare for a coding interview in python hi th...   \n",
       "\n",
       "                                              Tokens  \n",
       "0  [megha, your, profile, is, getting, hits, plea...  \n",
       "1  [building, a, logistic, regression, in, python...  \n",
       "2  [help, us, protect, you, security, advice, fro...  \n",
       "3  [megha, start, a, conversation, with, your, ne...  \n",
       "4  [prepare, for, a, coding, interview, in, pytho...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pick every message and convert it into tokens\n",
    "\n",
    "def identify_tokens(row):\n",
    "    message = row['Message']\n",
    "    tokens = word_tokenize(message)\n",
    "    token_words = [w for w in tokens if w.isalpha()]\n",
    "    return token_words\n",
    "\n",
    "mails_dataset['Tokens'] = mails_dataset.apply(identify_tokens, axis=1)\n",
    "mails_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F. Stemming / Lemmatization\n",
    "\n",
    "Both processes reduce the inflectional forms of word into a common base or root. But we are using lemmatization because it takes care of the context, while stemming simply performs crude cutoff..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nstemming = PorterStemmer()\\nsample_mail = mails_dataset.iloc[0]\\ntokens = sample_mail['Tokens']\\nstemmed_list = [stemming.stem(word) for word in tokens]\\nstemmed_list\\n\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "stemming = PorterStemmer()\n",
    "sample_mail = mails_dataset.iloc[0]\n",
    "tokens = sample_mail['Tokens']\n",
    "stemmed_list = [stemming.stem(word) for word in tokens]\n",
    "stemmed_list\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['megha',\n",
       " 'your',\n",
       " 'profile',\n",
       " 'is',\n",
       " 'getting',\n",
       " 'hit',\n",
       " 'please',\n",
       " 'view',\n",
       " 'this',\n",
       " 'email',\n",
       " 'in',\n",
       " 'a',\n",
       " 'browser',\n",
       " 'if',\n",
       " 'you',\n",
       " 'need',\n",
       " 'assistance',\n",
       " 'or',\n",
       " 'have',\n",
       " 'question',\n",
       " 'please',\n",
       " 'contact',\n",
       " 'linkedin',\n",
       " 'customer',\n",
       " 'service',\n",
       " 'this',\n",
       " 'is',\n",
       " 'an',\n",
       " 'occasional',\n",
       " 'email',\n",
       " 'to',\n",
       " 'help',\n",
       " 'you',\n",
       " 'get',\n",
       " 'the',\n",
       " 'most',\n",
       " 'out',\n",
       " 'of',\n",
       " 'linkedin',\n",
       " 'unsubscribe',\n",
       " 'this',\n",
       " 'email',\n",
       " 'wa',\n",
       " 'intended',\n",
       " 'for',\n",
       " 'megha',\n",
       " 'learn',\n",
       " 'why',\n",
       " 'we',\n",
       " 'include',\n",
       " 'this',\n",
       " 'httphelplinkedincomappanswersglobalidfteng',\n",
       " 'copyright',\n",
       " 'linkedin',\n",
       " 'corporation',\n",
       " 'all',\n",
       " 'right',\n",
       " 'reserved',\n",
       " 'linkedin',\n",
       " 'corp',\n",
       " 'west',\n",
       " 'maude',\n",
       " 'avenue',\n",
       " 'sunnyvale',\n",
       " 'ca']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer() \n",
    "\n",
    "sample_mail = mails_dataset.iloc[0]\n",
    "tokens = sample_mail['Tokens']\n",
    "lemmatize_list = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "lemmatize_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DocID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Message</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>megha your profile is getting hits please view...</td>\n",
       "      <td>[megha, your, profile, is, getting, hit, pleas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>building a logistic regression in python step ...</td>\n",
       "      <td>[building, a, logistic, regression, in, python...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>help us protect you security advice from googl...</td>\n",
       "      <td>[help, u, protect, you, security, advice, from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>megha start a conversation with your new conne...</td>\n",
       "      <td>[megha, start, a, conversation, with, your, ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>prepare for a coding interview in python hi th...</td>\n",
       "      <td>[prepare, for, a, coding, interview, in, pytho...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DocID  Label                                            Message  \\\n",
       "0      1      1  megha your profile is getting hits please view...   \n",
       "1      2      3  building a logistic regression in python step ...   \n",
       "2      3      0  help us protect you security advice from googl...   \n",
       "3      4      1  megha start a conversation with your new conne...   \n",
       "4      5      4  prepare for a coding interview in python hi th...   \n",
       "\n",
       "                                              Tokens  \n",
       "0  [megha, your, profile, is, getting, hit, pleas...  \n",
       "1  [building, a, logistic, regression, in, python...  \n",
       "2  [help, u, protect, you, security, advice, from...  \n",
       "3  [megha, start, a, conversation, with, your, ne...  \n",
       "4  [prepare, for, a, coding, interview, in, pytho...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lemmatize_tokens(row):\n",
    "    tokens = row['Tokens']\n",
    "    lemmatized_list = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return (lemmatized_list)\n",
    "\n",
    "mails_dataset['Tokens'] = mails_dataset.apply(lemmatize_tokens, axis=1)\n",
    "mails_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### G. Remove stopwords\n",
    "\n",
    "Stopwords are common words that carry less important meaning than keywords. So, we will remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'me', 'these', 'can', 'm', 'very', 'with', 'to', 'when', 'is', \"shan't\", 'from', 'her', 'itself', 'and', 'aren', \"didn't\", 'because', \"you'd\", 'same', \"should've\", 'its', 'such', 'were', 'after', 'before', 'most', 'needn', 'which', 'won', \"aren't\", 'too', \"hasn't\", 'she', 'ain', 'this', 'in', 'the', 'now', 'them', \"shouldn't\", 'hers', 'while', 'we', \"haven't\", \"you've\", 'his', \"isn't\", 'themselves', 'where', 'yours', \"you're\", 'over', 'mustn', 'at', \"weren't\", 'been', 'out', 'y', \"mightn't\", 'yourself', 'only', 'once', 'shouldn', 'through', 'under', 'here', 'my', 'wouldn', 'he', 'our', 'has', 'yourselves', 'am', 'what', 'own', 'herself', 'have', 'be', 'don', 'for', 'your', 'will', \"doesn't\", 'o', 'hasn', 'as', 'should', 'being', 'd', 'having', 'more', 'wasn', 'not', 't', \"wouldn't\", 'had', 'll', 'a', 'haven', 'there', 's', \"she's\", 're', 'why', 'hadn', 'couldn', 'below', \"wasn't\", 'do', 'about', 'ours', \"hadn't\", \"don't\", 'no', 'just', 'against', 'nor', 'did', 'until', 'ma', 'weren', 'myself', 'mightn', 'who', 'on', 'are', \"won't\", \"mustn't\", 'that', 'some', 'their', \"you'll\", 'during', 'other', 'it', 'i', 'above', \"that'll\", 'than', 'didn', 'himself', 'those', 'by', 'him', 'all', 'both', \"couldn't\", 'isn', 'you', 'they', 'few', 'again', 'theirs', 'into', \"it's\", 'up', 'any', 'between', 'doesn', \"needn't\", 'or', 'if', 'how', 'further', 'does', 'but', 'so', 'of', 'ourselves', 'shan', 'down', 'off', 'then', 've', 'whom', 'doing', 'each', 'an', 'was'}\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "print(stop_words,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DocID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Message</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>megha your profile is getting hits please view...</td>\n",
       "      <td>[megha, profile, getting, hit, please, view, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>building a logistic regression in python step ...</td>\n",
       "      <td>[building, logistic, regression, python, step,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>help us protect you security advice from googl...</td>\n",
       "      <td>[help, u, protect, security, advice, google, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>megha start a conversation with your new conne...</td>\n",
       "      <td>[megha, start, conversation, new, connection, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>prepare for a coding interview in python hi th...</td>\n",
       "      <td>[prepare, coding, interview, python, hi, new, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DocID  Label                                            Message  \\\n",
       "0      1      1  megha your profile is getting hits please view...   \n",
       "1      2      3  building a logistic regression in python step ...   \n",
       "2      3      0  help us protect you security advice from googl...   \n",
       "3      4      1  megha start a conversation with your new conne...   \n",
       "4      5      4  prepare for a coding interview in python hi th...   \n",
       "\n",
       "                                              Tokens  \n",
       "0  [megha, profile, getting, hit, please, view, e...  \n",
       "1  [building, logistic, regression, python, step,...  \n",
       "2  [help, u, protect, security, advice, google, c...  \n",
       "3  [megha, start, conversation, new, connection, ...  \n",
       "4  [prepare, coding, interview, python, hi, new, ...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_stopwords(row):\n",
    "    tokens = row['Tokens']\n",
    "    filtered_list = [w for w in tokens if not w in stop_words]\n",
    "    return (filtered_list)\n",
    "\n",
    "mails_dataset['Tokens'] = mails_dataset.apply(remove_stopwords , axis=1)\n",
    "mails_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### >>>> Now our data is clean and ready for further processing <<<<"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 5: CREATING DOCUMENT TERM MATRIX\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Convert each document to a count vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'megha profile getting hit please view email browser need assistance question please contact linkedin customer service occasional email help get linkedin unsubscribe email wa intended megha learn include httphelplinkedincomappanswersglobalidfteng copyright linkedin corporation right reserved linkedin corp west maude avenue sunnyvale ca'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#list of tokens are combined to create the message\n",
    "\n",
    "tkn = mails_dataset['Tokens'].iloc[0]\n",
    "msg = ' '.join(tkn) \n",
    "msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['megha profile getting hit please view email browser need assistance question please contact linkedin customer service occasional email help get linkedin unsubscribe email wa intended megha learn include httphelplinkedincomappanswersglobalidfteng copyright linkedin corporation right reserved linkedin corp west maude avenue sunnyvale ca',\n",
       " 'building logistic regression python step step susan li towards data science today highlight building logistic regression python step step logistic regression machine learning classification algorithm used predict probability ofâ susan li towards data science min read topic modeling data visualization pythonflask recently became interested data visualization topic modeling python one problem withâ ethan jarrell hackernooncom min read building beautiful command line interface python building command line interface using python oyetoke tobi emmanuel codeburst min read introduction environment variable use decoupling configuration application jim medlock chingu min read quick read lifechanging magic enough would happen stopped constantly lifting eye next target ryan holiday forge min read comparison lightweight document classification model keep simple grant holtes dataseries min read automate sending email python using spreadsheet self explanatory title love spreadsheet min read based reading history principal component analysis dimensionality reduction learn perform pca learning mathematics behind algorithm executing stepbystep withâ lorraine li towards data science min read classification regression analysis decision tree learn build classification regression decision tree lorraine li towards data science min read simple introduction knearest neighbor algorithm knn dhilip subramanian towards data science min read best science explosive science epigenetics health choice make today could affect expression kid grandkids dnaââand maybeâ markham heid elemental min read science created factory farming science could end alternative meat company like beyond meat impossible burger could upend conventional agriculture byâ marc gunther onezero min read best mindfulness addiction psychiatrist explains use brain science break bad habit break bad habit control craving mind thomas oppong personal growth min read said question consider daily selfinterview prompt awareness focus growth ryan holiday human part min read question ask lifechanging power regular selfinquiry darius foroux forge min read read give sign turn magical thinking face big decision timothy kreider human part min read react someone ghosted commits suicide anger felt ha turned confusion attempt grieve something never really teo yu siang human part min read make email better tailor topic sent medium po box san francisco ca unsubscribe visit',\n",
       " 'help u protect security advice google confirm recovery phone google use phone number make sure itâs really get locked account notice suspicious activity confirm recovery phone number see personalized security recommendation security checkup take action worried clicking link visit security checkup httpsmyaccountgooglecomsecuritycheckup received email let know important change google account service â google llc amphitheatre parkway mountain view ca usa',\n",
       " 'megha start conversation new connection kashish kashish gupta ha accepted invitation let start conversation kashish gupta assistant professor acharya narendra dev college new delhi area india view profile message start conversation kashish kashish thanks connecting hope youre well start note unsubscribe help receiving accepted invitation email email wa intended megha sundriyal student department computer science university delhi learn included â linkedin ireland unlimited company wilton plaza wilton place dublin linkedin registered business name linkedin ireland unlimited company linkedin linkedin logo registered trademark linkedin',\n",
       " 'prepare coding interview python hi new course covering python sql take unique preparing coding interview question python course gain confidence codingbased question would encounter technical coding interview sa user gain gentle introduction language every chapter sa user course providing detailed mapping function sa procedure highlighting similarity difference weâre also launching one new coding challenge intermediate finance finally check five course toprated datacamp user course â sql server function manipulating data â preparing coding interview question python â writing function python â exploratory data analysis python â cleaning data apache spark python â hyperparameter tuning python â sa user â network analysis case study â singlecell rnaseq workflow â longitudinal analysis coding challenge â intermediate finance course recommended datacamp user â intermediate sql server â big data fundamental via pyspark â introduction tensorflow python â introduction matplotlib python â forecasting using arima model python happy learning datacamp team datacamp inc fifth avenue suite new york ny unsubscribe']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = []                          #list of prepocessed documents, where each term is the text of the document\n",
    "for row in range(total_mails):\n",
    "    tkn = mails_dataset['Tokens'].iloc[row]\n",
    "    msg = ' '.join(tkn)\n",
    "    corpus.append(msg)\n",
    "\n",
    "corpus[:5]   #print first 5 instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aakanksha</th>\n",
       "      <th>aanchal</th>\n",
       "      <th>aanchalguptasrccgmailcom</th>\n",
       "      <th>aanshul</th>\n",
       "      <th>aap</th>\n",
       "      <th>aapne</th>\n",
       "      <th>aaron</th>\n",
       "      <th>aarora</th>\n",
       "      <th>aashna</th>\n",
       "      <th>...</th>\n",
       "      <th>ââthe</th>\n",
       "      <th>âââââââââââââââââââââââââââââ</th>\n",
       "      <th>âï</th>\n",
       "      <th>âïâ</th>\n",
       "      <th>ãzler</th>\n",
       "      <th>ðââï</th>\n",
       "      <th>ðâðð</th>\n",
       "      <th>ððð</th>\n",
       "      <th>ðððð</th>\n",
       "      <th>ðððððððððð</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7666 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aa  aakanksha  aanchal  aanchalguptasrccgmailcom  aanshul  aap  aapne  \\\n",
       "0   0          0        0                         0        0    0      0   \n",
       "1   0          0        0                         0        0    0      0   \n",
       "2   0          0        0                         0        0    0      0   \n",
       "3   0          0        0                         0        0    0      0   \n",
       "4   0          0        0                         0        0    0      0   \n",
       "\n",
       "   aaron  aarora  aashna  ...  ââthe  âââââââââââââââââââââââââââââ  âï  âïâ  \\\n",
       "0      0       0       0  ...      0                              0   0    0   \n",
       "1      0       0       0  ...      0                              0   0    0   \n",
       "2      0       0       0  ...      0                              0   0    0   \n",
       "3      0       0       0  ...      0                              0   0    0   \n",
       "4      0       0       0  ...      0                              0   0    0   \n",
       "\n",
       "   ãzler  ðââï  ðâðð  ððð  ðððð  ðððððððððð  \n",
       "0      0     0     0    0     0           0  \n",
       "1      0     0     0    0     0           0  \n",
       "2      0     0     0    0     0           0  \n",
       "3      0     0     0    0     0           0  \n",
       "4      0     0     0    0     0           0  \n",
       "\n",
       "[5 rows x 7666 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#document term matrix\n",
    "vec = CountVectorizer()\n",
    "X = vec.fit_transform(corpus)\n",
    "df = pd.DataFrame(X.toarray(), columns = vec.get_feature_names())\n",
    "df.head()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7666"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_dim = len(vec.get_feature_names())   #dimension of each vector\n",
    "vector_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['aa', 'aakanksha', 'aanchal', ..., 'ððð', 'ðððð', 'ðððððððððð'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms = np.array(df.columns.values)\n",
    "terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_matrix = df.values\n",
    "df_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_normalized = preprocessing.normalize(df_matrix, norm='l2')\n",
    "df_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aakanksha</th>\n",
       "      <th>aanchal</th>\n",
       "      <th>aanchalguptasrccgmailcom</th>\n",
       "      <th>aanshul</th>\n",
       "      <th>aap</th>\n",
       "      <th>aapne</th>\n",
       "      <th>aaron</th>\n",
       "      <th>aarora</th>\n",
       "      <th>aashna</th>\n",
       "      <th>...</th>\n",
       "      <th>ââthe</th>\n",
       "      <th>âââââââââââââââââââââââââââââ</th>\n",
       "      <th>âï</th>\n",
       "      <th>âïâ</th>\n",
       "      <th>ãzler</th>\n",
       "      <th>ðââï</th>\n",
       "      <th>ðâðð</th>\n",
       "      <th>ððð</th>\n",
       "      <th>ðððð</th>\n",
       "      <th>ðððððððððð</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7666 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    aa  aakanksha  aanchal  aanchalguptasrccgmailcom  aanshul  aap  aapne  \\\n",
       "0  0.0        0.0      0.0                       0.0      0.0  0.0    0.0   \n",
       "1  0.0        0.0      0.0                       0.0      0.0  0.0    0.0   \n",
       "2  0.0        0.0      0.0                       0.0      0.0  0.0    0.0   \n",
       "3  0.0        0.0      0.0                       0.0      0.0  0.0    0.0   \n",
       "4  0.0        0.0      0.0                       0.0      0.0  0.0    0.0   \n",
       "\n",
       "   aaron  aarora  aashna  ...  ââthe  âââââââââââââââââââââââââââââ   âï  âïâ  \\\n",
       "0    0.0     0.0     0.0  ...    0.0                            0.0  0.0  0.0   \n",
       "1    0.0     0.0     0.0  ...    0.0                            0.0  0.0  0.0   \n",
       "2    0.0     0.0     0.0  ...    0.0                            0.0  0.0  0.0   \n",
       "3    0.0     0.0     0.0  ...    0.0                            0.0  0.0  0.0   \n",
       "4    0.0     0.0     0.0  ...    0.0                            0.0  0.0  0.0   \n",
       "\n",
       "   ãzler  ðââï  ðâðð  ððð  ðððð  ðððððððððð  \n",
       "0    0.0   0.0   0.0  0.0   0.0         0.0  \n",
       "1    0.0   0.0   0.0  0.0   0.0         0.0  \n",
       "2    0.0   0.0   0.0  0.0   0.0         0.0  \n",
       "3    0.0   0.0   0.0  0.0   0.0         0.0  \n",
       "4    0.0   0.0   0.0  0.0   0.0         0.0  \n",
       "\n",
       "[5 rows x 7666 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unit_vectors = pd.DataFrame(data=df_normalized, columns=terms)\n",
    "unit_vectors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DocID</th>\n",
       "      <th>Label</th>\n",
       "      <th>aa</th>\n",
       "      <th>aakanksha</th>\n",
       "      <th>aanchal</th>\n",
       "      <th>aanchalguptasrccgmailcom</th>\n",
       "      <th>aanshul</th>\n",
       "      <th>aap</th>\n",
       "      <th>aapne</th>\n",
       "      <th>aaron</th>\n",
       "      <th>...</th>\n",
       "      <th>ââthe</th>\n",
       "      <th>âââââââââââââââââââââââââââââ</th>\n",
       "      <th>âï</th>\n",
       "      <th>âïâ</th>\n",
       "      <th>ãzler</th>\n",
       "      <th>ðââï</th>\n",
       "      <th>ðâðð</th>\n",
       "      <th>ððð</th>\n",
       "      <th>ðððð</th>\n",
       "      <th>ðððððððððð</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7668 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   DocID  Label   aa  aakanksha  aanchal  aanchalguptasrccgmailcom  aanshul  \\\n",
       "0      1      1  0.0        0.0      0.0                       0.0      0.0   \n",
       "1      2      3  0.0        0.0      0.0                       0.0      0.0   \n",
       "2      3      0  0.0        0.0      0.0                       0.0      0.0   \n",
       "3      4      1  0.0        0.0      0.0                       0.0      0.0   \n",
       "4      5      4  0.0        0.0      0.0                       0.0      0.0   \n",
       "\n",
       "   aap  aapne  aaron  ...  ââthe  âââââââââââââââââââââââââââââ   âï  âïâ  \\\n",
       "0  0.0    0.0    0.0  ...    0.0                            0.0  0.0  0.0   \n",
       "1  0.0    0.0    0.0  ...    0.0                            0.0  0.0  0.0   \n",
       "2  0.0    0.0    0.0  ...    0.0                            0.0  0.0  0.0   \n",
       "3  0.0    0.0    0.0  ...    0.0                            0.0  0.0  0.0   \n",
       "4  0.0    0.0    0.0  ...    0.0                            0.0  0.0  0.0   \n",
       "\n",
       "   ãzler  ðââï  ðâðð  ððð  ðððð  ðððððððððð  \n",
       "0    0.0   0.0   0.0  0.0   0.0         0.0  \n",
       "1    0.0   0.0   0.0  0.0   0.0         0.0  \n",
       "2    0.0   0.0   0.0  0.0   0.0         0.0  \n",
       "3    0.0   0.0   0.0  0.0   0.0         0.0  \n",
       "4    0.0   0.0   0.0  0.0   0.0         0.0  \n",
       "\n",
       "[5 rows x 7668 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create final dtm. column 0 will tell the document number while column 1 will tell the label. \n",
    "\n",
    "dtm = pd.concat([mails_dataset,unit_vectors], axis=1, ignore_index=False, sort=False).reset_index(drop=True)\n",
    "drop_list = ['Message', 'Tokens']\n",
    "dtm.drop(drop_list, axis = 1, inplace=True)\n",
    "dtm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### >>>Now every document in the corpus has a vector representation<<<"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 6: CREATING TEST AND TRAIN SETS\n",
    "\n",
    "We will randomly split our dataset in 80–20 ratio. Where 80% of the total data will be used as training set and rest 20% will be considered as test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dtm.drop('Label',axis=1) \n",
    "y = dtm['Label']\n",
    "\n",
    "#random state = 0, will give same split evry time. \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instance in :\n",
      " Training set =  544 \n",
      " Test set =  137\n"
     ]
    }
   ],
   "source": [
    "test_size, train_size = X_test.shape[0], X_train.shape[0]\n",
    "print(\"Number of instance in :\\n Training set = \", train_size, \"\\n Test set = \", test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DocID</th>\n",
       "      <th>aa</th>\n",
       "      <th>aakanksha</th>\n",
       "      <th>aanchal</th>\n",
       "      <th>aanchalguptasrccgmailcom</th>\n",
       "      <th>aanshul</th>\n",
       "      <th>aap</th>\n",
       "      <th>aapne</th>\n",
       "      <th>aaron</th>\n",
       "      <th>aarora</th>\n",
       "      <th>...</th>\n",
       "      <th>ââthe</th>\n",
       "      <th>âââââââââââââââââââââââââââââ</th>\n",
       "      <th>âï</th>\n",
       "      <th>âïâ</th>\n",
       "      <th>ãzler</th>\n",
       "      <th>ðââï</th>\n",
       "      <th>ðâðð</th>\n",
       "      <th>ððð</th>\n",
       "      <th>ðððð</th>\n",
       "      <th>ðððððððððð</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>514</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>312</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>133</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>904</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7667 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     DocID   aa  aakanksha  aanchal  aanchalguptasrccgmailcom  aanshul  aap  \\\n",
       "200    263  0.0        0.0      0.0                       0.0      0.0  0.0   \n",
       "380    514  0.0        0.0      0.0                       0.0      0.0  0.0   \n",
       "236    312  0.0        0.0      0.0                       0.0      0.0  0.0   \n",
       "101    133  0.0        0.0      0.0                       0.0      0.0  0.0   \n",
       "667    904  0.0        0.0      0.0                       0.0      0.0  0.0   \n",
       "\n",
       "     aapne  aaron  aarora  ...  ââthe  âââââââââââââââââââââââââââââ   âï  \\\n",
       "200    0.0    0.0     0.0  ...    0.0                            0.0  0.0   \n",
       "380    0.0    0.0     0.0  ...    0.0                            0.0  0.0   \n",
       "236    0.0    0.0     0.0  ...    0.0                            0.0  0.0   \n",
       "101    0.0    0.0     0.0  ...    0.0                            0.0  0.0   \n",
       "667    0.0    0.0     0.0  ...    0.0                            0.0  0.0   \n",
       "\n",
       "     âïâ  ãzler  ðââï  ðâðð  ððð  ðððð  ðððððððððð  \n",
       "200  0.0    0.0   0.0   0.0  0.0   0.0         0.0  \n",
       "380  0.0    0.0   0.0   0.0  0.0   0.0         0.0  \n",
       "236  0.0    0.0   0.0   0.0  0.0   0.0         0.0  \n",
       "101  0.0    0.0   0.0   0.0  0.0   0.0         0.0  \n",
       "667  0.0    0.0   0.0   0.0  0.0   0.0         0.0  \n",
       "\n",
       "[5 rows x 7667 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label\n",
       "200      1\n",
       "380      3\n",
       "236      2\n",
       "101      0\n",
       "667      0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y_train is an array. so in order to concat it with our X variables, we need to convert it into dataframe\n",
    "\n",
    "labels_train = pd.DataFrame(y_train, columns = ['Label'])\n",
    "labels_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DocID</th>\n",
       "      <th>aa</th>\n",
       "      <th>aakanksha</th>\n",
       "      <th>aanchal</th>\n",
       "      <th>aanchalguptasrccgmailcom</th>\n",
       "      <th>aanshul</th>\n",
       "      <th>aap</th>\n",
       "      <th>aapne</th>\n",
       "      <th>aaron</th>\n",
       "      <th>aarora</th>\n",
       "      <th>...</th>\n",
       "      <th>âââââââââââââââââââââââââââââ</th>\n",
       "      <th>âï</th>\n",
       "      <th>âïâ</th>\n",
       "      <th>ãzler</th>\n",
       "      <th>ðââï</th>\n",
       "      <th>ðâðð</th>\n",
       "      <th>ððð</th>\n",
       "      <th>ðððð</th>\n",
       "      <th>ðððððððððð</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>514</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>312</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>133</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>904</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7668 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   DocID   aa  aakanksha  aanchal  aanchalguptasrccgmailcom  aanshul  aap  \\\n",
       "0    263  0.0        0.0      0.0                       0.0      0.0  0.0   \n",
       "1    514  0.0        0.0      0.0                       0.0      0.0  0.0   \n",
       "2    312  0.0        0.0      0.0                       0.0      0.0  0.0   \n",
       "3    133  0.0        0.0      0.0                       0.0      0.0  0.0   \n",
       "4    904  0.0        0.0      0.0                       0.0      0.0  0.0   \n",
       "\n",
       "   aapne  aaron  aarora  ...  âââââââââââââââââââââââââââââ   âï  âïâ  ãzler  \\\n",
       "0    0.0    0.0     0.0  ...                            0.0  0.0  0.0    0.0   \n",
       "1    0.0    0.0     0.0  ...                            0.0  0.0  0.0    0.0   \n",
       "2    0.0    0.0     0.0  ...                            0.0  0.0  0.0    0.0   \n",
       "3    0.0    0.0     0.0  ...                            0.0  0.0  0.0    0.0   \n",
       "4    0.0    0.0     0.0  ...                            0.0  0.0  0.0    0.0   \n",
       "\n",
       "   ðââï  ðâðð  ððð  ðððð  ðððððððððð  Label  \n",
       "0   0.0   0.0  0.0   0.0         0.0      1  \n",
       "1   0.0   0.0  0.0   0.0         0.0      3  \n",
       "2   0.0   0.0  0.0   0.0         0.0      2  \n",
       "3   0.0   0.0  0.0   0.0         0.0      0  \n",
       "4   0.0   0.0  0.0   0.0         0.0      0  \n",
       "\n",
       "[5 rows x 7668 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    We have X_train, y_train, X_test, y_test.\n",
    "    Using these lists and dataframes we will randomly create two non-overlapping datasets \n",
    "        1. training set\n",
    "        2. testing set\n",
    "'''\n",
    "\n",
    "#creating training set\n",
    "train_dtm = pd.concat([X_train, labels_train], axis = 1).reset_index(drop=True)\n",
    "train_dtm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DocID</th>\n",
       "      <th>aa</th>\n",
       "      <th>aakanksha</th>\n",
       "      <th>aanchal</th>\n",
       "      <th>aanchalguptasrccgmailcom</th>\n",
       "      <th>aanshul</th>\n",
       "      <th>aap</th>\n",
       "      <th>aapne</th>\n",
       "      <th>aaron</th>\n",
       "      <th>aarora</th>\n",
       "      <th>...</th>\n",
       "      <th>âââââââââââââââââââââââââââââ</th>\n",
       "      <th>âï</th>\n",
       "      <th>âïâ</th>\n",
       "      <th>ãzler</th>\n",
       "      <th>ðââï</th>\n",
       "      <th>ðâðð</th>\n",
       "      <th>ððð</th>\n",
       "      <th>ðððð</th>\n",
       "      <th>ðððððððððð</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>146</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>805</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>337</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>373</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7668 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   DocID   aa  aakanksha  aanchal  aanchalguptasrccgmailcom  aanshul  aap  \\\n",
       "0    146  0.0        0.0      0.0                       0.0      0.0  0.0   \n",
       "1    805  0.0        0.0      0.0                       0.0      0.0  0.0   \n",
       "2    337  0.0        0.0      0.0                       0.0      0.0  0.0   \n",
       "3    750  0.0        0.0      0.0                       0.0      0.0  0.0   \n",
       "4    373  0.0        0.0      0.0                       0.0      0.0  0.0   \n",
       "\n",
       "   aapne  aaron  aarora  ...  âââââââââââââââââââââââââââââ   âï  âïâ  ãzler  \\\n",
       "0    0.0    0.0     0.0  ...                            0.0  0.0  0.0    0.0   \n",
       "1    0.0    0.0     0.0  ...                            0.0  0.0  0.0    0.0   \n",
       "2    0.0    0.0     0.0  ...                            0.0  0.0  0.0    0.0   \n",
       "3    0.0    0.0     0.0  ...                            0.0  0.0  0.0    0.0   \n",
       "4    0.0    0.0     0.0  ...                            0.0  0.0  0.0    0.0   \n",
       "\n",
       "   ðââï  ðâðð  ððð  ðððð  ðððððððððð  Label  \n",
       "0   0.0   0.0  0.0   0.0         0.0      1  \n",
       "1   0.0   0.0  0.0   0.0         0.0      1  \n",
       "2   0.0   0.0  0.0   0.0         0.0      3  \n",
       "3   0.0   0.0  0.0   0.0         0.0      0  \n",
       "4   0.0   0.0  0.0   0.0         0.0      0  \n",
       "\n",
       "[5 rows x 7668 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our training set is ready, similarly creating test set\n",
    "\n",
    "labels_test = pd.DataFrame(y_test, columns = ['Label'])\n",
    "test_dtm = pd.concat([X_test, labels_test], axis = 1).reset_index(drop=True)\n",
    "test_dtm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 7: TRAINING CLASSIFIER\n",
    "\n",
    "Calculate centroids of each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_classes = dtm['Label'].nunique()\n",
    "total_classes      # total number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_instances = np.zeros(total_classes)\n",
    "for ci in range(total_classes):\n",
    "    \n",
    "    for example in range(train_size):\n",
    "        label = train_dtm['Label'].iloc[example]\n",
    "        if(label==ci):\n",
    "            class_instances[ci] = class_instances[ci] + 1     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([194., 121., 113.,  89.,  27.])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0002829  0.         0.00354664 ... 0.00103093 0.00072179 0.        ]\n",
      " [0.         0.000528   0.000616   ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "class_centroids = np.ndarray((total_classes, vector_dim))         #empty array\n",
    "class_set = {}           #divide the instances into classes\n",
    "\n",
    "for ci in range(total_classes):\n",
    "    class_set[ci] = train_dtm[train_dtm['Label'] == ci].drop(['DocID','Label'],axis=1)     \n",
    "    \n",
    "    #count number of instances in the class\n",
    "    count_instances = len(class_set[ci])\n",
    "    \n",
    "    #mean of each column in the separated dataset\n",
    "    class_centroids[ci] = class_set[ci].mean(axis = 0)    #axis=0: column wise\n",
    "    \n",
    "print(class_centroids)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 8: TESTING CLASSIFIER\n",
    "\n",
    "Predicting the output class for the every instance in the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Compute distance / similarity\n",
    "\n",
    "Calculate distance between test data and each example of training data using Euclidean distance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_dtm.iloc[2][1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Function to calculate Euclidean distance between two vectors. \n",
    "      -  One is test vector(whose class is to be predicted)\n",
    "      -  Other is given example(whose class is known)\n",
    "\n",
    "'''\n",
    "\n",
    "def euclideanDistance(test_case, data, vector_dim):\n",
    "    distance = 0        \n",
    "    i =  1                      #starting from position 1, as position 0 contains DocID\n",
    "    for i in range(vector_dim):          \n",
    "        distance += pow((test_case[i] - data[i]), 2)          #formula for Euclidean Distance\n",
    "    return math.sqrt(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "337.0012696239774"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1 = test_dtm.iloc[2]\n",
    "d2 = train_dtm.iloc[5]\n",
    "distance = euclideanDistance(d1, class_centroids[0], vector_dim)\n",
    "distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Predict the class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "def predictClass(test_case):\n",
    "    distances = []\n",
    "    \n",
    "    for ci in range(total_classes):\n",
    "        centroid = class_centroids[ci]\n",
    "        dist = euclideanDistance(test_case, centroid, vector_dim)\n",
    "        distances.append((ci, dist))  #store (Class,Distance from test_case)\n",
    "        \n",
    "    dis = dict(distances)                                           # key : DocID, value : Distance       \n",
    "    sorted_distances = sorted(dis.items(), key=operator.itemgetter(1))     #itemgetter(1): sort on values\n",
    "     \n",
    "    pclass = sorted_distances[0][0]\n",
    "    return pclass           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_dtm.iloc[3]\n",
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictClass(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    \n",
    "'''       \n",
    "predictions = []                       #to store prediction of each test example\\\n",
    "\n",
    "for row in range(test_size): \n",
    "    test_case = test_dtm.iloc[row]\n",
    "\n",
    "    #predict the class label for each example and append to the predictions list\n",
    "    predictions.append(predictClass(test_case))\n",
    "\n",
    "#predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Testing is over ! </b>\n",
    "<br>We have predicted labels for each sample in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 8: ACCURACY OF THE CLASSIFIER\n",
    "\n",
    "Accuracy is the fraction of correct predictions our model out of total predictions. \n",
    "Formally, accuracy has the following definition:\n",
    "<br><br>\n",
    "<center><b> Accuracy = (Number of correct predictions) / (Number of total predictions) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******* Test Set Examples ******* :  137\n",
      "******* Test Set Accuracy ******* :  32.11678832116788 %\n"
     ]
    }
   ],
   "source": [
    "#calculate accuracy\n",
    "predict_labels = np.array(predictions)\n",
    "actual_labels = np.array(test_dtm['Label'])\n",
    "\n",
    "test_accuracy = np.sum(predict_labels == actual_labels)/float(test_size) \n",
    "\n",
    "print (\"******* Test Set Examples ******* : \", test_size)\n",
    "print (\"******* Test Set Accuracy ******* : \", (test_accuracy*100) ,\"%\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[44  0  0  0  0]\n",
      " [30  0  0  0  0]\n",
      " [28  0  0  0  0]\n",
      " [30  0  0  0  0]\n",
      " [ 5  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(actual_labels, predict_labels)\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#true_negative\n",
    "TN = [0]*total_classes\n",
    "#false_negative\n",
    "FN = [0]*total_classes\n",
    "#false_positive\n",
    "FP = [0]*total_classes\n",
    "#true_positive\n",
    "TP = [0]*total_classes\n",
    "\n",
    "for class_no in range(total_classes):\n",
    "    for i in range(total_classes):\n",
    "        for j in range(total_classes):\n",
    "            if(i==j and i==class_no):\n",
    "                TP[class_no] = conf_matrix[i][j]\n",
    "            if(i!=class_no and j!=class_no):\n",
    "                TN[class_no] += conf_matrix[i][j]\n",
    "            if(i==class_no and j!=class_no):\n",
    "                FN[class_no] += conf_matrix[i][j]\n",
    "            if(j==class_no and i!=class_no):\n",
    "                FP[class_no] += conf_matrix[i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ CLASSIFICATION PERFORMANCE OF THE NAIVE BAYES MODEL ------ \n",
      " class :  0 \n",
      " Recall :  100.0 %\n",
      " Precision :  32.11678832116788 %\n",
      " F-measure :  48.61878453038674 %\n",
      "------ CLASSIFICATION PERFORMANCE OF THE NAIVE BAYES MODEL ------ \n",
      " class :  1 \n",
      " Recall :  0.0 %\n",
      " Precision :  nan %\n",
      " F-measure :  nan %\n",
      "------ CLASSIFICATION PERFORMANCE OF THE NAIVE BAYES MODEL ------ \n",
      " class :  2 \n",
      " Recall :  0.0 %\n",
      " Precision :  nan %\n",
      " F-measure :  nan %\n",
      "------ CLASSIFICATION PERFORMANCE OF THE NAIVE BAYES MODEL ------ \n",
      " class :  3 \n",
      " Recall :  0.0 %\n",
      " Precision :  nan %\n",
      " F-measure :  nan %\n",
      "------ CLASSIFICATION PERFORMANCE OF THE NAIVE BAYES MODEL ------ \n",
      " class :  4 \n",
      " Recall :  0.0 %\n",
      " Precision :  nan %\n",
      " F-measure :  nan %\n",
      "\n",
      " Accuracy :  72.84671532846716 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Megha_Mayank\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "correct=0\n",
    "total=0\n",
    "for class_no in range(total_classes):\n",
    "    # Recall is the ratio of the total number of correctly classified positive examples divided by the total number of positive examples. \n",
    "    # High Recall indicates the class is correctly recognized (small number of FN)\n",
    "    recall = (TP[class_no])/(TP[class_no] + FN[class_no])\n",
    "\n",
    "    # Precision is the the total number of correctly classified positive examples divided by the total number of predicted positive examples. \n",
    "    # High Precision indicates an example labeled as positive is indeed positive (small number of FP)\n",
    "    precision = (TP[class_no])/(TP[class_no] + FP[class_no])\n",
    "\n",
    "    fmeasure = (2*recall*precision)/(recall+precision)\n",
    "    correct+=TP[class_no]+TN[class_no]\n",
    "    total+=TN[class_no] + FN[class_no] + FP[class_no] + TP[class_no]\n",
    "    print(\"------ CLASSIFICATION PERFORMANCE OF THE NAIVE BAYES MODEL ------ \"\\\n",
    "      \"\\n class : \", class_no, \\\n",
    "      \"\\n Recall : \", (recall*100) ,\"%\" \\\n",
    "      \"\\n Precision : \", (precision*100) ,\"%\" \\\n",
    "      \"\\n F-measure : \", (fmeasure*100) ,\"%\" )\n",
    "\n",
    "\n",
    "accuracy = correct/total\n",
    "print(\"\\n Accuracy : \", (accuracy*100) ,\"%\" )\n",
    "#accuracy_score(y_test, y_predict)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
